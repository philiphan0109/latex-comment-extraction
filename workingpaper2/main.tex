% RLC main.tex Version 2024.4

\documentclass[10pt]{article} % For LaTeX2e
%\usepackage{rlc}
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{rlc}
% To de-anonymize and remove mentions to RLC (for example, for posting to preprint servers), instead use the following:
% \usepackage[preprint]{rlc}

\usepackage{booktabs} % for professional tables
\newcommand{\algorithmautorefname}{Algorithm}



% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor={blue},citecolor={magenta},urlcolor={red}}  

\newcommand{\psc}[1]{\textcolor{blue}{\textbf{[psc: }#1\textbf{]}}}
\newcommand{\johan}[1]{\textcolor{red}{\textbf{[johan: }#1\textbf{]}}}
\newcommand{\joao}[1]{\textcolor{green}{\textbf{[joao: }#1\textbf{]}}}
\newcommand\sbullet[1][.5]{\mathbin{\vcenter{\hbox{\scalebox{#1}{$\bullet$}}}}}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{bbm}

\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{url}


\title{On the consistency of hyper-parameter selection in value-based deep reinforcement learning}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.
% \author{Johan Obando-Ceron\footnotemark[1]\\%\thanks{Equal contribution}
%       jobando0730@gmail.com \\
%       Mila - Québec AI Institute \\
%       Universit\'e de Montr\'eal \\
%       Google DeepMind
%       \And
%       João G.M. Araújo \thanks{Equal contribution}\\%\printfnsymbol{1}\\
%       joaogui@google.com \\
%       Google DeepMind
%       \And
%       Aaron Courville \\
%       aaron.courville@umontreal.ca \\
%       Mila - Québec AI Institute, Universit\'e de Montr\'eal \\
%       \And
%       Pablo Samuel Castro\\
%       psc@google.com\\
%       Google DeepMind\\
%       Mila - Québec AI Institute, Universit\'e de Montr\'eal \\
%       }


\author{Johan Obando-Ceron\(^{*1,2,3}\), João G.M. Araújo\(^{*3}\), Aaron Courville\(^{1,2}\), \\\textbf{Pablo Samuel Castro\(^{1,2,3}\)
}\\\\
Mila - Québec AI Institute\(^{1}\) \\
Universit\'e de Montr\'eal\(^{2}\) \\
Google DeepMind\(^{3}\)  \\
}


% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{June}  % Insert correct month for camera-ready version
\def\year{2024} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/pdf?id=szUyvvwoZB}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle
\blfootnote{*Authors contributed equally. Correspondence to \texttt{jobando0730@gmail.com},\texttt{[joaogui,psc]@google.com}}

\begin{abstract}
Deep reinforcement learning (deep RL) has achieved tremendous success on various domains through a combination of algorithmic design and careful selection of hyper-parameters. Algorithmic improvements are often the result of iterative enhancements built upon prior approaches, while hyper-parameter choices are typically inherited from previous methods or fine-tuned specifically for the proposed technique. Despite their crucial impact on performance, hyper-parameter choices are frequently overshadowed by algorithmic advancements. This paper conducts an extensive empirical study focusing on the reliability of hyper-parameter selection for value-based deep reinforcement learning agents, including the introduction of a new score to quantify the consistency and reliability of various hyper-parameters. Our findings not only help establish which hyper-parameters are most critical to tune, but also help clarify which tunings remain {\em consistent} across different training regimes.

\end{abstract}

\input{sections/introduction}
\input{sections/background}
\input{sections/experimental_details}
\input{sections/results}
%\input{sections/environment_properties}
\input{sections/relatedwork}
\input{sections/discussion}

\bibliography{main}
\bibliographystyle{rlc}

\newpage
\appendix
\input{sections/appendix}

\end{document}
